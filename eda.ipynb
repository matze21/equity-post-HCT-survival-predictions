{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = pd.read_csv('data_dictionary.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = train.columns\n",
    "col2 = test.columns\n",
    "list((set(col1)-set(col2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = train.select_dtypes(include=['object', 'category']).columns\n",
    "numerical_features = train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "categorical_features, numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in train.columns:\n",
    "    if f == 'ID':\n",
    "        continue\n",
    "    uniqueV = train[f].unique()\n",
    "    print('feature: ',f)\n",
    "    print('number of unique values: ', len(uniqueV))\n",
    "    print('number of missing values: ', train[f].isnull().sum(), np.round(train[f].isnull().sum()/len(train),2))\n",
    "    print('description: ', dic[dic['variable'] == f]['description'].values[0])\n",
    "    if len(uniqueV) < 30:\n",
    "        print(uniqueV)\n",
    "    print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['donor_age','age_at_hct']\n",
    "categorical = ['dri_score', 'psych_disturb', 'cyto_score', 'diabetes',\n",
    "       'hla_match_c_high', 'hla_high_res_8', 'tbi_status', 'arrhythmia',\n",
    "       'hla_low_res_6', 'graft_type', 'vent_hist', 'renal_issue',\n",
    "       'pulm_severe', 'prim_disease_hct', 'hla_high_res_6', 'cmv_status',\n",
    "       'hla_high_res_10', 'hla_match_dqb1_high', 'tce_imm_match', 'hla_nmdp_6',\n",
    "       'hla_match_c_low', 'rituximab', 'hla_match_drb1_low',\n",
    "       'hla_match_dqb1_low', 'prod_type', 'cyto_score_detail',\n",
    "       'conditioning_intensity', 'ethnicity', 'year_hct', 'obesity', 'mrd_hct',\n",
    "       'in_vivo_tcd', 'tce_match', 'hla_match_a_high', 'hepatic_severe',\n",
    "       'prior_tumor', 'hla_match_b_low', 'peptic_ulcer',\n",
    "       'hla_match_a_low', 'gvhd_proph', 'rheum_issue',\n",
    "       'sex_match', 'hla_match_b_high', 'race_group', 'comorbidity_score',\n",
    "       'karnofsky_score', 'hepatic_mild', 'tce_div_match', 'donor_related',\n",
    "       'melphalan_dose', 'hla_low_res_8', 'cardiac', 'hla_match_drb1_high',\n",
    "       'pulm_moderate', 'hla_low_res_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in numerical_features:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.hist(train[f], bins=50)\n",
    "    plt.title(f)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = train.groupby(['dri_score', 'efs'])['efs_time'].mean().unstack()\n",
    "\n",
    "# Rename columns for clarity\n",
    "result.columns = ['No Event', 'Event']\n",
    "\n",
    "# Reset index to make 'category' a column\n",
    "result = result.reset_index()\n",
    "\n",
    "# Sort by 'Event' median life expectancy descending\n",
    "result = result.sort_values('No Event', ascending=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = train['dri_score'].unique()\n",
    "for c in cat:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.hist(train[(train['dri_score'] == c) & (train['efs'] == 1)]['efs_time'], bins=50, color='red')\n",
    "    plt.hist(train[(train['dri_score'] == c) & (train['efs'] == 0)]['efs_time'], bins=50, color='blue', alpha=0.5)\n",
    "    plt.title(c)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class FeatureTransformer:\n",
    "    def __init__(self):\n",
    "        self.dummy_features = [\n",
    "            'dri_score', 'psych_disturb', 'diabetes', 'tbi_status', 'arrhythmia',\n",
    "            'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe', 'prim_disease_hct',\n",
    "            'cmv_status', 'tce_imm_match', 'rituximab', 'prod_type', 'ethnicity',\n",
    "            'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hepatic_severe',\n",
    "            'prior_tumor', 'peptic_ulcer', 'gvhd_proph', 'rheum_issue', 'sex_match',\n",
    "            'race_group', 'hepatic_mild', 'tce_div_match', 'donor_related', 'melphalan_dose',\n",
    "            'cardiac', 'pulm_moderate'\n",
    "        ]\n",
    "        \n",
    "        self.numeric_features = [\n",
    "            'cyto_score', 'hla_match_c_high', 'hla_high_res_8', 'hla_low_res_6',\n",
    "            'hla_high_res_6', 'hla_high_res_10', 'hla_match_dqb1_high', 'hla_nmdp_6',\n",
    "            'hla_match_c_low', 'hla_match_drb1_low', 'hla_match_dqb1_low',\n",
    "            'cyto_score_detail', 'conditioning_intensity', 'year_hct', 'hla_match_a_high',\n",
    "            'hla_match_b_low', 'hla_match_a_low', 'hla_match_b_high', 'comorbidity_score',\n",
    "            'karnofsky_score', 'hla_low_res_8', 'hla_match_drb1_high', 'hla_low_res_10',\n",
    "            'donor_age', 'age_at_hct'\n",
    "        ]\n",
    "        \n",
    "        self.encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        self.imputer = SimpleImputer(strategy='constant', fill_value='Missing')\n",
    "        self.numeric_imputer = SimpleImputer(strategy='median')\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "        self.cyto_score_rank = {'Favorable': 0, 'Intermediate': 1, 'Poor': 2, 'Other': 1.5, 'TBD': np.nan, 'Not tested': np.nan}\n",
    "        self.cyto_score_detail_rank = {'Favorable': 0, 'Intermediate': 1, 'Poor': 2, 'TBD': np.nan, 'Not tested': np.nan}\n",
    "        self.conditioning_intensity_rank = {'NMA': 0, 'RIC': 1, 'MAC': 2, 'TBD': np.nan, 'No drugs reported': np.nan, 'N/A, F(pre-TED) not submitted': np.nan}\n",
    "\n",
    "        self.earliest_year = None   \n",
    "\n",
    "    def fit(self, df):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Apply custom ranking for specific features\n",
    "        df['cyto_score'] = df['cyto_score'].map(self.cyto_score_rank)\n",
    "        df['cyto_score_detail'] = df['cyto_score_detail'].map(self.cyto_score_detail_rank)\n",
    "        df['conditioning_intensity'] = df['conditioning_intensity'].map(self.conditioning_intensity_rank)\n",
    "        \n",
    "        # Add age difference feature\n",
    "        df['age_difference'] = df['donor_age'] - df['age_at_hct']\n",
    "        \n",
    "        # Handle year_hct\n",
    "        self.earliest_year = df['year_hct'].min()\n",
    "        df['years_since_first_hct'] = df['year_hct'] - self.earliest_year\n",
    "        \n",
    "        # Update numeric_features list\n",
    "        self.numeric_features = [f for f in self.numeric_features if f != 'year_hct'] + ['age_difference', 'years_since_first_hct']\n",
    "        \n",
    "        # Now proceed with the rest of the fitting process\n",
    "        imputed_data = self.imputer.fit_transform(df[self.dummy_features])\n",
    "        self.numeric_imputer.fit(df[self.numeric_features])\n",
    "        self.scaler.fit(df[self.numeric_features])\n",
    "        \n",
    "        # Fit the encoder on the imputed data\n",
    "        self.encoder.fit(imputed_data)\n",
    "\n",
    "    def transform(self, df):\n",
    "        df_transformed = df.copy()\n",
    "        \n",
    "        # Apply custom ranking for specific features\n",
    "        df_transformed['cyto_score'] = df_transformed['cyto_score'].map(self.cyto_score_rank)\n",
    "        df_transformed['cyto_score_detail'] = df_transformed['cyto_score_detail'].map(self.cyto_score_detail_rank)\n",
    "        df_transformed['conditioning_intensity'] = df_transformed['conditioning_intensity'].map(self.conditioning_intensity_rank)\n",
    "        \n",
    "        # Add age difference feature\n",
    "        df_transformed['age_difference'] = df_transformed['donor_age'] - df_transformed['age_at_hct']\n",
    "        \n",
    "        # Handle year_hct\n",
    "        df_transformed['years_since_first_hct'] = df_transformed['year_hct'] - self.earliest_year\n",
    "        df_transformed = df_transformed.drop(columns=['year_hct'])\n",
    "        \n",
    "        # Handle numeric features\n",
    "        for feature in self.numeric_features:\n",
    "            if feature in df_transformed.columns:\n",
    "                df_transformed[feature] = pd.to_numeric(df_transformed[feature], errors='coerce')\n",
    "        \n",
    "        # Impute missing values in numeric features\n",
    "        df_transformed[self.numeric_features] = self.numeric_imputer.transform(df_transformed[self.numeric_features])\n",
    "        \n",
    "        # Normalize numeric values\n",
    "        df_transformed[self.numeric_features] = self.scaler.transform(df_transformed[self.numeric_features])\n",
    "        \n",
    "        # Handle categorical features\n",
    "        imputed_data = self.imputer.transform(df_transformed[self.dummy_features])\n",
    "        dummy_encoded = self.encoder.transform(imputed_data)\n",
    "        dummy_columns = self.encoder.get_feature_names_out(self.dummy_features)\n",
    "        dummy_df = pd.DataFrame(dummy_encoded, columns=dummy_columns, index=df_transformed.index)\n",
    "        \n",
    "        # Drop original dummy features and concatenate encoded features\n",
    "        df_transformed = df_transformed.drop(columns=self.dummy_features)\n",
    "        df_transformed = pd.concat([df_transformed, dummy_df], axis=1)\n",
    "        \n",
    "        # Handle 'efs' separately as it's binary\n",
    "        if 'efs' in df_transformed.columns:\n",
    "            df_transformed['efs'] = df_transformed['efs'].astype(int)\n",
    "        \n",
    "        return df_transformed\n",
    "\n",
    "\n",
    "\n",
    "# Usage:\n",
    "transformer = FeatureTransformer()\n",
    "transformer.fit(train)\n",
    "train_transformed = transformer.transform(train)\n",
    "#test_transformed = transformer.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# target investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['efs'] == 1].efs_time.hist(bins=100)\n",
    "train.loc[train['efs'] == 0].efs_time.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
