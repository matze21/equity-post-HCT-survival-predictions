{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate a kaplan meier curve per race and use that as a target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = pd.read_csv('data_dictionary.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "for race in train['race_group'].unique():\n",
    "    mask = train['race_group'] == race\n",
    "    kmf.fit(train[mask]['efs_time'], train[mask]['efs'], label=race)\n",
    "    kmf.plot()\n",
    "\n",
    "plt.title('Kaplan-Meier Curves by Race Group')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Survival Probability')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmf_models = {}\n",
    "for race in train['race_group'].unique():\n",
    "    kmf = KaplanMeierFitter()\n",
    "    mask = train['race_group'] == race\n",
    "    kmf.fit(train[mask]['efs_time'], train[mask]['efs'], label=race)\n",
    "    kmf_models[race] = kmf\n",
    "\n",
    "def get_survival_probability(row):\n",
    "    race = row['race_group']\n",
    "    time = row['efs_time']\n",
    "    return kmf_models[race].survival_function_at_times(time).iloc[0]\n",
    "\n",
    "train['survival_probability'] = train.apply(get_survival_probability, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['log_survival_probability'] = np.log(train['survival_probability']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "qt = QuantileTransformer(n_quantiles=1000, output_distribution='normal', random_state=42)\n",
    "train['q_survival_probability'] = qt.fit_transform(train['survival_probability'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['survival_probability','log_survival_probability','q_survival_probability']].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.plot.scatter(y='log_survival_probability', x='efs_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMV = [\"ID\",\"efs\",\"efs_time\",\"y\", 'efs_time2','log_survival_probability']\n",
    "FEATURES = [c for c in train.columns if not c in RMV]\n",
    "print(f\"There are {len(FEATURES)} FEATURES: {FEATURES}\")\n",
    "\n",
    "CATS = []\n",
    "for c in FEATURES:\n",
    "    if train[c].dtype==\"object\":\n",
    "        CATS.append(c)\n",
    "        train[c] = train[c].fillna(\"NAN\")\n",
    "        test[c] = test[c].fillna(\"NAN\")\n",
    "print(f\"In these features, there are {len(CATS)} CATEGORICAL FEATURES: {CATS}\")\n",
    "\n",
    "combined = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "#print(\"Combined data shape:\", combined.shape )\n",
    "\n",
    "# LABEL ENCODE CATEGORICAL FEATURES\n",
    "print(\"We LABEL ENCODE the CATEGORICAL FEATURES: \",end=\"\")\n",
    "for c in FEATURES:\n",
    "\n",
    "    # LABEL ENCODE CATEGORICAL AND CONVERT TO INT32 CATEGORY\n",
    "    if c in CATS:\n",
    "        print(f\"{c}, \",end=\"\")\n",
    "        combined[c],_ = combined[c].factorize()\n",
    "        combined[c] -= combined[c].min()\n",
    "        combined[c] = combined[c].astype(\"int32\")\n",
    "        combined[c] = combined[c].astype(\"category\")\n",
    "        \n",
    "    # REDUCE PRECISION OF NUMERICAL TO 32BIT TO SAVE MEMORY\n",
    "    else:\n",
    "        if combined[c].dtype==\"float64\":\n",
    "            combined[c] = combined[c].astype(\"float32\")\n",
    "        if combined[c].dtype==\"int64\":\n",
    "            combined[c] = combined[c].astype(\"int32\")\n",
    "    \n",
    "train_df_split0 = combined.iloc[:len(train)].copy()\n",
    "#test_df_split = combined.iloc[len(train):].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_split, test_df_split = train_test_split(train_df_split0, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "qtDict = {}\n",
    "for r in train_df_split['race_group'].unique():\n",
    "    mask = train_df_split['race_group'] == r\n",
    "    qt = QuantileTransformer(n_quantiles=1000, output_distribution='normal', random_state=42)\n",
    "    train_df_split.loc[mask,'q_survival_probability'] = qt.fit_transform(train_df_split.loc[mask,'survival_probability'].values.reshape(-1, 1))\n",
    "    qtDict[r] = qt\n",
    "\n",
    "qt = QuantileTransformer(n_quantiles=1000, output_distribution='normal', random_state=42)\n",
    "train_df_split['q_survival_probability'] = qt.fit_transform(train_df_split['survival_probability'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = train_df_split.drop(['ID', 'efs', 'efs_time','survival_probability','log_survival_probability','q_survival_probability'], axis=1).columns\n",
    "train_df_split.reset_index(inplace=True)\n",
    "test_df_split.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "FOLDS = 5\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "oof_xgb = np.zeros(len(train_df_split))\n",
    "pred_xgb = np.zeros(len(test_df_split))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df_split)):\n",
    "\n",
    "    print(\"#\"*25)\n",
    "    print(f\"### Fold {i+1}\")\n",
    "    print(\"#\"*25)\n",
    "    \n",
    "    x_train = train_df_split.loc[train_index,FEATURES].copy()\n",
    "    y_train = train_df_split.loc[train_index,\"q_survival_probability\"]\n",
    "    x_valid = train_df_split.loc[test_index,FEATURES].copy()\n",
    "    y_valid = train_df_split.loc[test_index,\"q_survival_probability\"]\n",
    "    x_test = test_df_split[FEATURES].copy()\n",
    "\n",
    "    dtrain = xgboost.DMatrix(x_train, label=y_train, enable_categorical=True)\n",
    "    dvalid = xgboost.DMatrix(x_valid, label=y_valid, enable_categorical=True)\n",
    "\n",
    "    model_xgb = XGBRegressor(\n",
    "        max_depth=3,  \n",
    "        colsample_bytree=0.5, \n",
    "        subsample=0.8, \n",
    "        n_estimators=10_000,  \n",
    "        learning_rate=0.1, \n",
    "        early_stopping_rounds=25,\n",
    "        #objective='reg:logistic',\n",
    "        enable_categorical=True,\n",
    "        min_child_weight=5,\n",
    "        eval_metric= \"mae\",\n",
    "    )\n",
    "    model_xgb.fit(\n",
    "        x_train, y_train,\n",
    "        eval_set=[(x_train, y_train), (x_valid, y_valid)],  \n",
    "        verbose=100 \n",
    "    )\n",
    "\n",
    "    # INFER OOF\n",
    "    oof_xgb[test_index] = model_xgb.predict(x_valid)\n",
    "    # INFER TEST\n",
    "    pred_xgb += model_xgb.predict(x_test)\n",
    "\n",
    "# COMPUTE AVERAGE TEST PREDS\n",
    "pred_xgb /= FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metric import score\n",
    "\n",
    "y_trueCV = train_df_split[[\"ID\",\"efs\",\"efs_time\",\"race_group\",'survival_probability']].copy()\n",
    "y_predCV = train_df_split[[\"ID\"]].copy()\n",
    "y_predCV[\"prediction\"] = oof_xgbR #higher risk should lead to lower value, so our prediction is just simply a risk score\n",
    "m, ar0 = score(y_trueCV.copy(), y_predCV.copy(), \"ID\")\n",
    "\n",
    "y_true = test_df_split[[\"ID\",\"efs\",\"efs_time\",\"race_group\",'survival_probability']].copy()\n",
    "y_pred = test_df_split[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = pred_xgbR #higher risk should lead to lower value, so our prediction is just simply a risk score\n",
    "n, ar1 = score(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "#print(f\"\\nOverall CV for XGBoost =\",m)\n",
    "#print(f\"\\nOverall test for XGBoost =\",n)\n",
    "print(f\"CV: {m} | Test: {n}\")\n",
    "#print(f\"c-indexes: CV: {ar0} | Test: {ar1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model_xgb.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": FEATURES,  # Replace FEATURES with your list of feature names\n",
    "    \"Importance\": feature_importance\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "plt.figure(figsize=(10, 15))\n",
    "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"XGBoost KaplanMeier Feature Importance\")\n",
    "plt.gca().invert_yaxis()  # Flip features for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# investigation of transformed target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trueCV = train_df_split[[\"ID\",\"efs\",\"efs_time\",\"race_group\",'survival_probability','q_survival_probability']].copy()\n",
    "y_trueCV[\"prediction\"] = oof_xgb\n",
    "y_trueCV[\"predictionR\"] = qt.inverse_transform(oof_xgb.reshape(-1,1))\n",
    "\n",
    "y_true = test_df_split[[\"ID\",\"efs\",\"efs_time\",\"race_group\",'survival_probability','q_survival_probability']].copy()\n",
    "y_true[\"prediction\"] = pred_xgb\n",
    "y_true[\"predictionR\"] = qt.inverse_transform(pred_xgb.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trueCV[['q_survival_probability','prediction']].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in y_trueCV['race_group'].unique():\n",
    "    mask = y_trueCV['race_group'] == r\n",
    "    y_trueCV.loc[mask,'predictionR'] = qtDict[r].inverse_transform(y_trueCV.loc[mask,'prediction'].values.reshape(-1, 1))\n",
    "    print(r)\n",
    "    y_trueCV.loc[mask,['q_survival_probability','prediction']].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trueCV.loc[y_trueCV['q_survival_probability'] < -3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trueCV.loc[y_trueCV.race_group ==2].plot.scatter(y='survival_probability', x='efs_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true.loc[y_true.race_group ==2].plot.scatter(y='survival_probability', x='efs_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trueCV[['survival_probability','predictionR']].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
